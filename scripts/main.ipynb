{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import environ\n",
    "import json\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from elasticsearch import Elasticsearch\n",
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подключение установлено.\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(\n",
    "    environ.get('ELASTIC_URL'),\n",
    "    basic_auth=(environ.get('ELASTIC_USER'), environ.get('ELASTIC_PASSWORD')),\n",
    "    verify_certs=True\n",
    ")\n",
    "\n",
    "if es.ping():\n",
    "    print(\"Подключение установлено.\")\n",
    "else:\n",
    "    print(\"Не удалось подключиться к Elasticsearch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 'documents' создан\n"
     ]
    }
   ],
   "source": [
    "index_name = \"documents\"\n",
    "\n",
    "mappings = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"document_name\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"page_number\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"paragraph_number\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"text\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"lemmatized_text\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"bbox\": {\n",
    "                \"type\": \"float\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, body=mappings)\n",
    "    print(f\"Индекс '{index_name}' создан\")\n",
    "else:\n",
    "    print(f\"Индекс '{index_name}' уже существует\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "spell = SpellChecker(language='ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    words = text.split()\n",
    "    corrected_words = []\n",
    "\n",
    "    for word in words:\n",
    "        corrected_word = spell.correction(word)\n",
    "        if corrected_word is None:\n",
    "            corrected_word = word\n",
    "        corrected_words.append(corrected_word)\n",
    "    \n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "    return lemmatized_text\n",
    "\n",
    "def preprocess_text(text): return lemmatize_text(correct_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '../jsons/elasticsearch_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pdf_path, 'r', encoding='utf-8') as f:\n",
    "    documents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:58<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "page_number = 0\n",
    "for doc in tqdm(documents[:50]): # всего 150 записей, потому что все записи даже одного документа обрабатывались бы час\n",
    "    doc[\"lemmatized_text\"] = preprocess_text(doc['text'])\n",
    "    es.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Железнодорожный транспотр\" # ошибка допущена специально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Name: 7enYF2uL5kFZlOOpQhLl0nUT91RjCbeR.pdf\n",
      "Page Number: 1\n",
      "Paragraph Number: 10\n",
      "bbox: [70.94400024414062, 570.1958618164062, 527.9199829101562, 678.9252319335938]\n",
      "Text: обеспечить реализацию Стратегии. 5. Мониторинг реализации Стратегии и ведение транспортно- экономического баланса Российской Федерации возложить на федеральное государственное бюджетное учреждение \"Научный центр по комплексным транспортным проблемам Министерства транспорта Российской  Федерации\". \n",
      "------\n",
      "Document Name: 7enYF2uL5kFZlOOpQhLl0nUT91RjCbeR.pdf\n",
      "Page Number: 5\n",
      "Paragraph Number: 2\n",
      "bbox: [70.94400024414062, 73.0687255859375, 528.1300048828125, 161.5251922607422]\n",
      "Text: Стратегические направления развития евразийской экономической  интеграции до 2025 года, утвержденные решением Высшего Евразийского экономического совета от 11 декабря 2020 г. № 12, а также иные акты и решения органов Евразийского экономического союза в части транспорта. \n",
      "------\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"lemmatized_text\": {\n",
    "                \"query\": preprocess_text(query_text),\n",
    "                \"minimum_should_match\": \"80%\"\n",
    "            } \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=query)\n",
    "\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(f\"Document Name: {hit['_source']['document_name']}\")\n",
    "    print(f\"Page Number: {hit['_source']['page_number']}\")\n",
    "    print(f\"Paragraph Number: {hit['_source']['paragraph_number']}\")\n",
    "    print(f\"bbox: {hit['_source']['bbox']}\")\n",
    "    print(f\"Text: {hit['_source']['text']}\")\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняю нижний блок для быстрого пересоздания индекса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = es.indices.delete(index=index_name, ignore=[400, 404])\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
